<div align="center">

# ğŸ§  PhantomLink

### Real-Time Neural Data Streaming Server for BCI Development

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/license-Research-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-MVP_Complete-success.svg)](https://github.com/yelabb/PhantomLink)
[![Data Analysis](https://img.shields.io/badge/ğŸ“Š_Data_Analysis-Notebook-orange.svg)](notebooks/data_analysis.ipynb)
[![Beginner's Guide](https://img.shields.io/badge/ğŸ“š_Beginner's_Guide-Learn-blue.svg)](docs/BEGINNERS_GUIDE.md)

**The Ethereal/Mailtrap for Neurotechnology**

*Stream pre-recorded neural data at 40Hz with microsecond precision, simulating live brain-computer interface signals for decoder development, calibration workflows, and ground truth validation.*

> **New to Brain-Computer Interfaces?** Check out our [Complete Beginner's Guide](docs/BEGINNERS_GUIDE.md) for an educational introduction to BCIs, neural data, and how PhantomLink works!

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [API Documentation](#-api-reference) â€¢ [Architecture](#-architecture) â€¢ [Contributing](#-contributing) â€¢ [ğŸ“š Beginner's Guide](docs/BEGINNERS_GUIDE.md)

</div>

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Key Features](#-features)
- [Quick Start](#-quick-start)
- [Architecture](#-architecture)
- [API Reference](#-api-reference)
- [Use Cases](#-use-cases)
- [Development](#-development)
- [Testing](#-testing)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

**PhantomLink** is a high-performance neural data streaming server designed for brain-computer interface (BCI) research and development. It replays real neural recordings from the MC_Maze dataset at 40Hz with strict 25ms timing intervals, enabling developers to:

- **Develop BCI Decoders**: Train and test decoding algorithms with real neural data
- **Calibration Workflows**: Filter streams by target intention or trial ID for decoder calibration
- **Multi-User Testing**: Isolate independent sessions with shareable URLs (ChatGPT-style architecture)
- **Ground Truth Validation**: Validate decoder predictions against actual target positions
- **Performance Benchmarking**: Test decoder throughput and latency under realistic conditions

### What Makes PhantomLink Special?

- ğŸ¯ **Real Neural Data**: Uses MC_Maze dataset (142 neural units, 294s, 100 trials) from the Neural Latents Benchmark
- âš¡ **40Hz Precision**: Sub-millisecond timing accuracy for realistic BCI simulation
- ğŸ”„ **Multi-Session Isolation**: Each user/experiment gets independent playback state
- ğŸšï¸ **Intent-Based Filtering**: Stream only packets matching specific targets or trials
- ğŸš€ **Production-Ready**: FastAPI + Uvicorn ASGI with async WebSocket streaming
- ğŸ’¾ **Memory Efficient**: Lazy-loaded NWB/HDF5 with memory-mapped access

---

## âœ¨ Features

### Core Capabilities

| Feature | Description |
|---------|-------------|
| **40Hz Real-Time Streaming** | WebSocket endpoint with sub-millisecond timing accuracy |
| **Multi-Session Architecture** | Independent streams with shareable URLs and automatic expiration |
| **Intent-Based Calibration** | Query trials by target, filter streams by intention |
| **Time-Aligned Payloads** | Spike counts + cursor kinematics + target intention synchronized to 25ms bins |
| **REST Control API** | Pause/resume/seek controls per session |
| **Trial Metadata API** | Query 100 trials with target positions and timing markers |
| **Lazy Loading** | Memory-mapped HDF5 access, no RAM bottleneck |
| **Built-in Validation** | Stream integrity testing and performance metrics |

### Data Stream Format

Each 40Hz packet contains:

```json
{
  "packet_id": 1234,
  "timestamp": 30.875,
  "spikes": {
    "spike_counts": [2, 0, 1, ...],  // 142 channels
    "channel_ids": [0, 1, 2, ...]
  },
  "kinematics": {
    "x": 125.3,
    "y": -78.9,
    "vx": 15.2,
    "vy": -8.4
  },
  "intention": {
    "trial_id": 42,
    "target_x": -77,
    "target_y": 82,
    "target_id": 1
  },
  "metadata": {
    "dataset": "MC_Maze",
    "frequency_hz": 40
  }
}
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.12+**
- **~2GB disk space** for neural dataset
- **Internet connection** for dataset download

### Installation

```bash
# Clone the repository
git clone https://github.com/yelabb/PhantomLink.git
cd PhantomLink

# Create and activate virtual environment
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/macOS
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Download Dataset

PhantomLink uses the MC_Maze dataset from the [DANDI Archive #000140](https://dandiarchive.org/dandiset/000140):

```bash
# Install DANDI CLI (if not already installed)
pip install dandi

# Download MC_Maze dataset
dandi download https://dandiarchive.org/dandiset/000140/draft

# Move to data directory
mkdir data
mv 000140/sub-Jenkins/* data/mc_maze.nwb
```

**Expected file location**: `data/mc_maze.nwb` (~1.5GB)

### Start Server

```bash
python main.py
```

You should see:

```
INFO - Starting PhantomLink Core server
INFO - Using NWB dataset: data\mc_maze.nwb
INFO - Initializing shared data loader: data\mc_maze.nwb
INFO - Found 142 neural units
INFO - Found 100 trials
INFO - Shared loader ready: 142 channels, 293.7s, 100 trials
INFO - Server ready on 0.0.0.0:8000
INFO - Session-based isolation enabled (max 10 sessions)
INFO - Uvicorn running on http://0.0.0.0:8000
```

ğŸ‰ **Server is running!** Visit `http://localhost:8000/docs` for interactive API documentation.

### Test the Stream

```bash
# Validate 40Hz streaming (10 seconds, 400 packets expected)
python test_client.py 10

# Test multi-session isolation
python test_multi_session.py

# Test calibration API
python test_calibration.py
```

---

## ğŸ—ï¸ Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PhantomLink Server                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   FastAPI    â”‚â—„â”€â”€â”€â”€â–ºâ”‚    Session Manager           â”‚    â”‚
â”‚  â”‚   Server     â”‚      â”‚  - Multi-session isolation   â”‚    â”‚
â”‚  â”‚              â”‚      â”‚  - LRU eviction              â”‚    â”‚
â”‚  â”‚  REST + WS   â”‚      â”‚  - Auto-cleanup (1hr TTL)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â–²                          â”‚                         â”‚
â”‚         â”‚                          â–¼                         â”‚
â”‚         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚    Client Requests     â”‚  Playback Engine(s)  â”‚             â”‚
â”‚                        â”‚  - 40Hz async loop   â”‚             â”‚
â”‚                        â”‚  - Pause/resume/seek â”‚             â”‚
â”‚                        â”‚  - Intent filtering  â”‚             â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                   â”‚                          â”‚
â”‚                                   â–¼                          â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚                        â”‚    Data Loader       â”‚             â”‚
â”‚                        â”‚  - Lazy NWB/HDF5     â”‚             â”‚
â”‚                        â”‚  - Memory-mapped     â”‚             â”‚
â”‚                        â”‚  - Trial metadata    â”‚             â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                   â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   mc_maze.nwb        â”‚
                         â”‚   (142 units, 294s)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

| Component | Responsibility |
|-----------|----------------|
| **server.py** | FastAPI app with REST + WebSocket endpoints, session management |
| **session_manager.py** | Multi-session orchestration, LRU eviction, auto-cleanup |
| **playback_engine.py** | 40Hz asyncio streaming loop with intent filtering |
| **data_loader.py** | Lazy NWB/HDF5 loader with trial metadata extraction |
| **models.py** | Pydantic data models for type safety and validation |
| **config.py** | Configuration settings (frequency, ports, limits) |

### Technology Stack

- **Web Framework**: FastAPI 0.109+ with Uvicorn ASGI server
- **Neural Data**: PyNWB 2.6+ with H5py for lazy HDF5 access
- **Async Runtime**: Python asyncio for concurrent streaming
- **Data Models**: Pydantic 2.5+ for type validation
- **WebSockets**: websockets 12.0 for real-time communication

### Performance Characteristics

| Metric | Value |
|--------|-------|
| Packet Generation | ~7ms (HDF5 read + binning) |
| Timing Precision | <1ms std deviation |
| Memory Footprint | <500MB (memory-mapped, shared across sessions) |
| Sustained Throughput | 40Hz for hours per session |
| Latency | 25ms Â± 0.5ms per packet |
| Session Overhead | ~50KB per session |
| Max Concurrent Sessions | 10 (configurable, LRU eviction) |
| Session TTL | 3600s (1 hour, auto-cleanup) |

---

## ğŸ“¡ API Reference

### Health Check

Check server status:

```bash
curl http://localhost:8000/health
```

Response:
```json
{
  "status": "healthy",
  "version": "0.2.0",
  "timestamp": "2026-01-12T13:30:00Z"
}
```

### Session Management

#### Create Session

Create a new isolated session with auto-generated or custom code:

```bash
# Auto-generated code (e.g., "swift-neural-42")
curl -X POST http://localhost:8000/api/sessions/create

# Custom code
curl -X POST http://localhost:8000/api/sessions/create \
  -H "Content-Type: application/json" \
  -d '{"custom_code": "my-experiment-1"}'
```

Response:
```json
{
  "session_code": "swift-neural-42",
  "stream_url": "ws://localhost:8000/stream/swift-neural-42",
  "created_at": "2026-01-12T13:30:00Z"
}
```

#### List Sessions

Get all active sessions with statistics:

```bash
curl http://localhost:8000/api/sessions
```

Response:
```json
{
  "sessions": {
    "swift-neural-42": {
      "created_at": "2026-01-12T13:30:00Z",
      "last_accessed": "2026-01-12T13:32:15Z",
      "active_connections": 2,
      "is_running": true,
      "current_packet": 150
    }
  },
  "total_sessions": 1
}
```

#### Get Session Details

```bash
curl http://localhost:8000/api/sessions/{session_code}
```

#### Delete Session

```bash
curl -X DELETE http://localhost:8000/api/sessions/{session_code}
```

#### Cleanup Expired Sessions

```bash
curl -X POST http://localhost:8000/api/sessions/cleanup
```

### WebSocket Streaming

#### Connect to Stream

```javascript
const ws = new WebSocket('ws://localhost:8000/stream/swift-neural-42');

ws.onmessage = (event) => {
  const packet = JSON.parse(event.data);
  console.log('Packet:', packet.data.packet_id);
  console.log('Spikes:', packet.data.spikes.spike_counts);
  console.log('Position:', packet.data.kinematics.x, packet.data.kinematics.y);
  console.log('Target:', packet.data.intention.target_x, packet.data.intention.target_y);
};
```

#### Filter by Target

Stream only packets reaching for a specific target:

```bash
ws://localhost:8000/stream/swift-neural-42?target_id=0
```

#### Filter by Trial

Stream only packets from a specific trial:

```bash
ws://localhost:8000/stream/swift-neural-42?trial_id=42
```

### Playback Control

Control playback for each session independently:

#### Pause Stream

```bash
curl -X POST http://localhost:8000/api/control/{session_code}/pause
```

#### Resume Stream

```bash
curl -X POST http://localhost:8000/api/control/{session_code}/resume
```

#### Seek to Position

```bash
curl -X POST http://localhost:8000/api/control/{session_code}/seek \
  -H "Content-Type: application/json" \
  -d '{"packet_id": 1000}'
```

#### Get Session Statistics

```bash
curl http://localhost:8000/api/stats/{session_code}
```

Response:
```json
{
  "session_code": "swift-neural-42",
  "is_running": true,
  "current_packet": 1234,
  "total_packets": 11748,
  "elapsed_seconds": 30.85,
  "active_connections": 2
}
```

### Trial Metadata

#### Get All Trials

```bash
curl http://localhost:8000/api/trials
```

Response:
```json
{
  "trials": [
    {
      "trial_id": 0,
      "start_time": 0.0,
      "stop_time": 2.95,
      "target_x": -118,
      "target_y": -83,
      "target_id": 0
    },
    ...
  ],
  "total_trials": 100
}
```

#### Get Trials by Target

```bash
curl http://localhost:8000/api/trials/by-target/{target_id}
```

#### Get Trial by ID

```bash
curl http://localhost:8000/api/trials/{trial_id}
```

---

## ğŸ’¡ Use Cases

### 1. Multi-User Calibration Sessions

Share independent calibration sessions with team members:

```python
import requests

# Team lead creates sessions for each user
users = ['alice', 'bob', 'charlie']
for user in users:
    response = requests.post(
        'http://localhost:8000/api/sessions/create',
        json={'custom_code': f'calibration-{user}'}
    )
    print(f"{user}: {response.json()['stream_url']}")

# Output:
# alice: ws://localhost:8000/stream/calibration-alice
# bob: ws://localhost:8000/stream/calibration-bob
# charlie: ws://localhost:8000/stream/calibration-charlie

# Each user streams independently
requests.post('http://localhost:8000/api/control/calibration-alice/pause')
# Bob and Charlie's streams continue unaffected
```

### 2. BCI Decoder Training

Train decoders with real neural data and known intentions:

```python
import websockets
import json
import asyncio

async def train_decoder():
    # Create dedicated training session
    response = requests.post(
        'http://localhost:8000/api/sessions/create',
        json={'custom_code': 'decoder-training-v1'}
    )
    stream_url = response.json()['stream_url']
    
    # Connect and collect training data
    async with websockets.connect(f'{stream_url}?target_id=0') as ws:
        training_data = []
        async for message in ws:
            packet = json.loads(message)['data']
            
            # Extract features
            spikes = packet['spikes']['spike_counts']
            target = (packet['intention']['target_x'], 
                     packet['intention']['target_y'])
            
            # Collect training examples
            training_data.append({'spikes': spikes, 'target': target})
            
            if len(training_data) >= 1000:
                break
        
        # Train your decoder
        decoder.fit(training_data)

asyncio.run(train_decoder())
```

### 3. Ground Truth Validation

Validate decoder predictions against actual targets:

```python
import websockets
import json
import asyncio
import numpy as np

async def validate_decoder(decoder):
    response = requests.post(
        'http://localhost:8000/api/sessions/create',
        json={'custom_code': 'validation-run1'}
    )
    stream_url = response.json()['stream_url']
    
    errors = []
    async with websockets.connect(stream_url) as ws:
        async for message in ws:
            packet = json.loads(message)['data']
            
            # Decoder prediction
            predicted = decoder.predict(packet['spikes']['spike_counts'])
            
            # Ground truth
            actual = (packet['intention']['target_x'],
                     packet['intention']['target_y'])
            
            # Calculate error
            error = np.linalg.norm(np.array(predicted) - np.array(actual))
            errors.append(error)
            
            if len(errors) >= 500:
                break
    
    print(f"Mean Error: {np.mean(errors):.2f}mm")
    print(f"Std Error: {np.std(errors):.2f}mm")

asyncio.run(validate_decoder(my_decoder))
```

### 4. Calibration Workflow

Build calibration datasets with specific targets:

```python
import requests

# Get all trials reaching for target 0
response = requests.get('http://localhost:8000/api/trials/by-target/0')
trials = response.json()['trials']  # 77 trials

# Create session for calibration
session = requests.post(
    'http://localhost:8000/api/sessions/create',
    json={'custom_code': 'calibration-target0'}
).json()

# Stream data from each calibration trial
for trial in trials[:10]:  # First 10 trials
    trial_id = trial['trial_id']
    stream_url = f"{session['stream_url']}?trial_id={trial_id}"
    # Connect to stream_url and collect calibration data
```

---

## ğŸ› ï¸ Development

### Project Structure

```
PhantomLink/
â”œâ”€â”€ data/                       # Neural datasets (gitignored)
â”‚   â””â”€â”€ mc_maze.nwb            # MC_Maze dataset (~1.5GB)
â”œâ”€â”€ config.py                  # Server configuration
â”œâ”€â”€ models.py                  # Pydantic data models
â”œâ”€â”€ data_loader.py             # NWB/HDF5 lazy loader
â”œâ”€â”€ playback_engine.py         # 40Hz streaming engine
â”œâ”€â”€ session_manager.py         # Multi-session orchestration
â”œâ”€â”€ server.py                  # FastAPI application
â”œâ”€â”€ main.py                    # Entry point
â”œâ”€â”€ test_client.py             # Stream validation
â”œâ”€â”€ test_calibration.py        # Calibration API tests
â”œâ”€â”€ test_multi_session.py      # Session isolation tests
â”œâ”€â”€ test_*.py                  # Unit/integration tests
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ pyproject.toml             # Project metadata
â””â”€â”€ README.md                  # This file
```

### Environment Setup

```bash
# Clone repository
git clone https://github.com/yelabb/PhantomLink.git
cd PhantomLink

# Create virtual environment
python -m venv .venv

# Activate environment
# Windows
.venv\Scripts\activate
# Linux/macOS
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install development dependencies
pip install pytest pytest-asyncio pytest-cov
```

### Adding a New Feature

Example: Add eye-tracking data to kinematics

**1. Update data model** ([models.py](models.py)):

```python
class Kinematics(BaseModel):
    x: float
    y: float
    vx: float
    vy: float
    eye_x: float  # New field
    eye_y: float  # New field
```

**2. Extend data loader** ([data_loader.py](data_loader.py)):

```python
def get_kinematics(self, start_time, end_time):
    # ... existing code ...
    
    # Extract eye tracking data
    eye_data = self._nwb.processing['behavior']['eye_pos'].data[start_idx:end_idx]
    
    return {
        **existing_data,
        'eye_x': eye_data[:, 0],
        'eye_y': eye_data[:, 1]
    }
```

**3. Update playback engine** ([playback_engine.py](playback_engine.py)):

```python
kinematics = Kinematics(
    x=..., y=..., vx=..., vy=...,
    eye_x=float(kinematics_data['eye_x'][0]),
    eye_y=float(kinematics_data['eye_y'][0])
)
```

### Development Workflow

```bash
# 1. Make changes
# Edit source files

# 2. Run tests
pytest -v

# 3. Start server
python main.py

# 4. Test changes
python test_client.py 10

# 5. Check coverage
pytest --cov=. --cov-report=html
```

### Code Style Guidelines

- âœ… **Type Hints**: All functions use type annotations
- âœ… **Async/Await**: All I/O operations are async
- âœ… **Logging**: Use `logger.info/warning/error` for diagnostics
- âœ… **Error Handling**: Fail fast, propagate errors clearly
- âœ… **No Mock Data**: Single source of truth from NWB files
- âœ… **Documentation**: Docstrings for all public functions

---

## ğŸ§ª Testing

PhantomLink includes comprehensive test coverage for all components.

### Quick Test Run

```bash
# Run all tests
pytest -v

# Windows batch file
test.bat
```

### Test Suites

```bash
# Unit tests only
pytest test_models.py test_data_loader.py test_playback_engine.py -v

# Integration tests
pytest test_server.py test_multi_session.py -v

# With coverage
pytest --cov=. --cov-report=html --cov-report=term-missing
```

### Manual Testing

```bash
# Validate 40Hz streaming for 10 seconds
python test_client.py 10

# View sample packets
python test_client.py sample

# Test session isolation
python test_multi_session.py

# Test calibration API
python test_calibration.py

# Filter by target
python test_calibration.py target 0

# Filter by trial
python test_calibration.py trial 5
```

### Expected Test Output

**Stream Validation**:
```
=== Stream Metadata ===
  dataset: MC_Maze
  total_packets: 11748
  frequency_hz: 40
  num_channels: 142

=== Validation Results ===
  packets_received: 400
  elapsed_seconds: 10.002
  actual_rate_hz: 39.99
  interval_mean_ms: 25.005
  interval_std_ms: 0.523
  sequence_gaps: 0

=== Timing Analysis ===
  âœ“ Interval timing: PASS (25.01ms â‰ˆ 25ms)
  âœ“ Stream rate: PASS (39.99Hz â‰ˆ 40Hz)
  âœ“ Sequence integrity: PASS (no gaps)
```

### Coverage Report

```bash
pytest --cov=. --cov-report=html
# Open htmlcov/index.html in browser
```

---

## ğŸ”§ Troubleshooting

### Common Issues

#### Port Already in Use

```bash
# Change port in config.py or use environment variable
# Windows
set PHANTOM_PORT=8001

# Linux/macOS
export PHANTOM_PORT=8001

# Then restart server
python main.py
```

#### Dataset Not Found

```bash
# Verify file exists
# Windows
dir data\mc_maze.nwb

# Linux/macOS
ls data/mc_maze.nwb

# Re-download if missing
dandi download https://dandiarchive.org/dandiset/000140/draft
```

#### Low Stream Rate (<40Hz)

- Check server logs for timing errors
- Verify NWB file is on SSD (not HDD)
- Ensure no other processes are accessing the file
- Check CPU usage (should be <10% per core)

```bash
# Get performance stats
curl http://localhost:8000/api/stats/{session_code}
```

#### Connection Refused

```bash
# Test health endpoint
curl http://localhost:8000/health

# List active sessions
curl http://localhost:8000/api/sessions

# Try 127.0.0.1 instead of localhost
ws://127.0.0.1:8000/stream/my-session
```

#### Session Not Found

```bash
# Create session explicitly
curl -X POST http://localhost:8000/api/sessions/create \
  -H "Content-Type: application/json" \
  -d '{"custom_code": "my-session"}'

# Or let WebSocket auto-create on connect
ws://localhost:8000/stream/my-session
```

#### Too Many Sessions

```bash
# Delete unused sessions
curl -X DELETE http://localhost:8000/api/sessions/{session_code}

# Trigger cleanup of expired sessions
curl -X POST http://localhost:8000/api/sessions/cleanup
```

### Performance Tuning

**Check current performance:**
```bash
curl http://localhost:8000/api/stats/{session_code}
```

**Optimize for higher throughput:**
- Use SSD storage for NWB file
- Close unnecessary background applications
- Increase process priority
- Monitor CPU usage

### Debug Mode

Enable verbose logging in [config.py](config.py):

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## ğŸ¤ Contributing

We welcome contributions from the BCI and neurotechnology community!

### How to Contribute

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes** with tests and documentation
4. **Run tests**: `pytest -v`
5. **Commit your changes**: `git commit -m 'Add amazing feature'`
6. **Push to branch**: `git push origin feature/amazing-feature`
7. **Open a Pull Request**

### Development Guidelines

- Write tests for new features
- Update documentation
- Follow existing code style
- Add type hints
- Use async/await for I/O operations
- Keep functions focused and testable

### Reporting Issues

Found a bug or have a feature request?

1. Check existing issues first
2. Provide detailed description
3. Include server logs if relevant
4. Share test output from `python test_client.py 10`

---

## ğŸ“š Additional Resources

- **Dataset**: [Neural Latents Benchmark](https://neurallatents.github.io/)
- **DANDI Archive**: [Dataset #000140](https://dandiarchive.org/dandiset/000140)
- **PyNWB Documentation**: [pynwb.readthedocs.io](https://pynwb.readthedocs.io/)
- **FastAPI Documentation**: [fastapi.tiangolo.com](https://fastapi.tiangolo.com/)

---

## ğŸ“„ License

This project is for **research use only**. The MC_Maze dataset is provided by the [Neural Latents Benchmark](https://neurallatents.github.io/) project.

---

## ğŸ—ºï¸ Roadmap

### Phase 2: Frontend Dashboard
- [ ] Real-time spike raster visualization
- [ ] Cursor trajectory plotting
- [ ] Decoder performance metrics
- [ ] Session management UI

### Phase 3: Decoder Integration
- [ ] Kalman filter decoder implementation
- [ ] Online calibration endpoint
- [ ] Ground truth comparison metrics
- [ ] A/B testing framework

### Phase 4: Multi-Dataset Support
- [ ] Switch between different NWB files
- [ ] Dataset selection API per session
- [ ] Unified metadata format
- [ ] Recording mode for saving streams

---

## ğŸ“ Contact

- **GitHub**: [@yelabb](https://github.com/yelabb)
- **Project**: [PhantomLink](https://github.com/yelabb/PhantomLink)
- **Issues**: [Report a bug](https://github.com/yelabb/PhantomLink/issues)

---

<div align="center">

**Built with â¤ï¸ for the BCI Community**

*Last Updated: January 12, 2026 â€¢ Version 0.2.0 â€¢ Status: âœ… MVP Complete*

[â¬† Back to Top](#-phantomlink)

</div>
